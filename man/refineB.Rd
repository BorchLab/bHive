% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/refineB.R
\name{refineB}
\alias{refineB}
\title{refineB: Gradient-based fine-tuning for bHIVE antibodies with multiple loss functions}
\usage{
refineB(
  A,
  X,
  y = NULL,
  assignments,
  task = c("clustering", "classification", "regression"),
  loss = c("categorical_crossentropy", "binary_crossentropy", "kullback_leibler",
    "cosine", "mse", "mae", "poisson", "huber"),
  steps = 5,
  lr = 0.01,
  push_away = TRUE,
  huber_delta = 1
)
}
\arguments{
\item{A}{Numeric matrix (nAb x d) of antibody/prototype positions.}

\item{X}{Matrix or data frame (nSamples x d) of feature data.}

\item{y}{Optional. Factor (classification), numeric (regression), or NULL (clustering).}

\item{assignments}{Integer vector (length=nSamples), specifying the antibody index
each sample belongs to (1..nAb).}

\item{task}{One of c("clustering","classification","regression").}

\item{loss}{One of c("categorical_crossentropy","binary_crossentropy",
"kullback_leibler","cosine","mse","mae","poisson","huber").}

\item{steps}{Integer. How many gradient steps to run.}

\item{lr}{Numeric. Learning rate for each update.}

\item{push_away}{Logical (for classification). Whether to push prototypes away
from differently-labeled samples.}

\item{huber_delta}{Numeric. The delta threshold if using huber loss.}
}
\value{
Updated matrix A of shape (nAb x d).
}
\description{
After running bHIVE (or honeycombHIVE), you have a set of final antibody positions (A)
in feature space. This function refines those prototypes by iterating over the
data points assigned to each antibody and applying small gradient-based updates
according to a user-chosen loss function.
}
\details{
The user must provide:
- A numeric matrix \code{A} of antibody/prototype positions (nAb x nFeatures).
- A numeric matrix/data frame \code{X} of data (nSamples x nFeatures).
- Optional \code{y} for classification/regression. If \code{task="clustering"},
  \code{y} can be NULL or ignored.
- An integer vector \code{assignments} (length = nSamples) giving the
  antibody index to which each data point is assigned (range 1..nAb).
  
## Available Losses

### Classification (factor y)
- **"categorical_crossentropy"**: Pull prototypes toward data points if they share
  the antibody's dominant label; push away otherwise.
- **"binary_crossentropy"**: Similar to categorical CE, but we interpret factor y
  as binary (two classes). Pull for same label, push for different label.
- **"kullback_leibler"**: Very rough approach that treats “dominant label vs. others”
  as p and q distributions, pushing/pulling prototypes.
- **"cosine"**: Interpreted as trying to maximize cosine similarity for same-label points
  and minimize for different-label points.

### Regression (numeric y)
- **"mse"**: Mean squared error approximation in feature space (pull prototypes
  toward assigned points).
- **"mae"**: Mean absolute error approach (sign-based pull).
- **"poisson"**: Poisson deviance (toy approach that scales the gradient by
  (pred - y)/pred if we stored a predicted rate; here we do a naive version).
- **"huber"**: Combines L1 and L2 regions, uses a delta cutoff. We adapt it
  to a naive per-point gradient in feature space.


This function does a simple mini-SGD loop over each data point in random order.
For classification, it identifies whether the data point shares the antibody's
"dominant label" and pulls/pushes accordingly. For regression/clustering, it
primarily pulls prototypes toward assigned points.
}
