% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/refineB.R
\name{refineB}
\alias{refineB}
\title{refineB: Gradient-based fine-tuning for bHIVE antibodies with multiple loss functions}
\usage{
refineB(
  A,
  X,
  y,
  assignments,
  loss = c("categorical_crossentropy", "binary_crossentropy", "kullback_leibler",
    "cosine", "mse", "mae", "poisson", "huber"),
  task = c("classification", "regression"),
  steps = 5,
  lr = 0.01,
  push_away = TRUE,
  huber_delta = 1
)
}
\arguments{
\item{A}{A matrix of antibody positions (nAntibodies x nFeatures).}

\item{X}{A matrix or data frame of data (nSamples x nFeatures).}

\item{y}{The target vector. For classification, a factor; for regression, numeric.}

\item{assignments}{Integer vector of length nSamples giving the antibody index
that each sample is assigned to (i.e. from \code{which.max(affinity)}).}

\item{loss}{Character. One of:
- classification: "categorical_crossentropy", "binary_crossentropy", "kullback_leibler", "cosine"
- regression: "mse", "mae", "poisson", "huber"}

\item{task}{Either "classification" or "regression".}

\item{steps}{How many gradient steps to run.}

\item{lr}{Learning rate for the gradient updates.}

\item{push_away}{Logical (classification only). If `TRUE`, prototypes are pushed away
from points with different labels. If `FALSE`, we only pull toward same-label points.}

\item{huber_delta}{Numeric, used for the "huber" loss threshold.}
}
\value{
A refined (updated) version of A with the same dimensions.
}
\description{
After running bHIVE (or honeycombHIVE), you have a set of final antibody positions (A)
in feature space. This function refines those prototypes by iterating over the
data points assigned to each antibody and applying small gradient-based updates
according to a user-chosen loss function.
}
\details{
## Classification vs. Regression
- **Classification**: The function pushes each antibody closer to data points of
  its "dominant" label, and optionally pushes it away from points of other labels.
  Multiple loss functions are conceptually adapted (naively) to prototype movement
  in feature space.
- **Regression**: The function pulls each antibody closer to the data points it
  represents, based on an approximate gradient for the chosen numeric loss (e.g. MSE, MAE).

## Available Losses

### Classification (factor y)
- **"categorical_crossentropy"**: Pull prototypes toward data points if they share
  the antibody's dominant label; push away otherwise.
- **"binary_crossentropy"**: Similar to categorical CE, but we interpret factor y
  as binary (two classes). Pull for same label, push for different label.
- **"kullback_leibler"**: Very rough approach that treats “dominant label vs. others”
  as p and q distributions, pushing/pulling prototypes.
- **"cosine"**: Interpreted as trying to maximize cosine similarity for same-label points
  and minimize for different-label points.

### Regression (numeric y)
- **"mse"**: Mean squared error approximation in feature space (pull prototypes
  toward assigned points).
- **"mae"**: Mean absolute error approach (sign-based pull).
- **"poisson"**: Poisson deviance (toy approach that scales the gradient by
  (pred - y)/pred if we stored a predicted rate; here we do a naive version).
- **"huber"**: Combines L1 and L2 regions, uses a delta cutoff. We adapt it
  to a naive per-point gradient in feature space.

In reality, each loss function is adapted in a **toy** manner to prototype
movement in feature space. True gradient-based training might require separate
parameters for the predicted label or value. This function demonstrates how you can
incorporate a variety of loss functions if you treat the **prototype** as a parameter
to be updated.
}
\examples{
X <- as.matrix(iris[, 1:4])  # Numeric features only

# Runnning bHIVE Classification
y <- iris$Species
res <- bHIVE(X = X, 
              y = y, 
              task = "classification", 
              nAntibodies = 30, 
              beta = 5, 
              epsilon = 0.01, 
              maxIter = 20, 
              k = 3, 
              verbose = FALSE)
              
 A <- res_bhive$antibodies
 assignments <- res_bhive$assignments 

#Refining Antibodies/Bees              
refineB(A,
                 X, 
                 y, 
                 assignments,
                 loss="mse", 
                 task="regression", 
                 steps=5, 
                 lr=0.01)

}
